
services:
  postgres:
    image: postgres:13
    container_name: etl_postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_PORT=${POSTGRES_PORT} # Agregado aquí
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"    # En este puerto se ejecutará el servidor de PostgreSQL
    networks:
      - etl-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 5s
      retries: 5
  streamlit:
    build:
      context: .
      dockerfile: docker/streamlit/Dockerfile
    container_name: etl_streamlit
    ports:
      - "8501:8501"   #En este puerto se ejecutará el servidor web de Streamlit
    volumes:
      - ./dashboard:/app
    depends_on:
      - postgres
    networks:
      - etl-network
    restart: always

  airflow-webserver:
    image: apache/airflow:2.7.1
    container_name: etl_airflow_webserver
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - ESIOS_TOKEN=${ESIOS_TOKEN}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY} # Configuración aquí
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data  # CAMBIAR ESTA LÍNEA
      - ./scripts:/scripts
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      retries: 5
    networks:
      - etl-network
    restart: always

  airflow-scheduler:
    image: apache/airflow:2.7.1
    container_name: etl_airflow_scheduler
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - ESIOS_TOKEN=${ESIOS_TOKEN}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY} # Configuración aquí
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data  # CAMBIAR ESTA LÍNEA
      - ./scripts:/scripts
    command: scheduler
    networks:
      - etl-network
    restart: always

  airflow-init:
    image: apache/airflow:2.7.1
    container_name: etl_airflow_init
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"
    networks:
      - etl-network

networks:
  etl-network:
    driver: bridge

volumes:
  postgres-db-volume: